## Runtime Scene Slices

Plan B from the AI-runtime discussion is now wired into the dev server. When a script jumps to `runtime/...` (for example `changeScene:runtime/ai-demo/entry.txt;`) the asset loader issues a request to `/games/<slug>/scene/runtime/ai-demo/entry.txt`.

### How it works

1. `packages/server/index.js` intercepts every `/games/:slug/scene/runtime/*.txt` request before the static middleware.
2. The request is passed to `packages/server/runtimeSceneProvider.js`.
3. `runtimeSceneProvider` either:
   - Delegates to a custom provider exported from the file pointed to `WEBGAL_RUNTIME_PROVIDER`, or
   - Falls back to the built-in demo slices that showcase a simple choose → branch → end flow.
4. The returned text is served as a regular WebGAL script, so the engine can keep parsing without any extra changes.

### Preparing a game

- Each game slug should contain `story/plan.json` describing premise/theme/outline, cast, signals (with min/max/desc/default), and golden_rules. This file is auto-generated by `scripts/gen.mjs` (it now emits both `plan.json` and the seed `scene/start.txt`, `scene/chapter_01/old_town.txt`). The runtime loader keeps the plan in memory and feeds the summary + rolling recaps/signals to the LLM prompt.
- The runtime server keeps a short recap buffer and signal table per slug. When a generated slice contains `setVar:signal=signal+1;`, that value is clamped to the range in `plan.json` and reflected back to the prompt for the next slices.
- 所有 `/games/<slug>/...` 静态资源都直接映射到 `packages/webgal/public/games`，因此 `scripts/gen.mjs` 写入的新故事可以「生成完马上玩」，无需重新 build dist。

### Lobby / 玩家副本

- 前端 Lobby 的 “AI 即刻生成” 按钮会调用 `POST /api/lobby/bootstrap`，请求体可包含：
  ```jsonc
  {
    "title": "可选：玩家命名/主题",
    "brief": "可选：玩家描述的风格/元素"
    // 不传 slug 时，服务器会自动创建唯一副本 slug
  }
  ```
- 请求必须带上 `X-WebGAL-Session` 头（由前端生成并长期保存），后端会把 plan/start/old_town 写入 `public/games/<slug>/`，并根据 plan.warmup.entry/depth 立即为该 session 预取 runtime 入口。
- 运行时的 recap/signal 也从“slug + session”两个维度隔离：同一游戏副本可供多人体验，但每名玩家（session）拥有独立的滚动剧情与状态表互不干扰。
- 如果需要发布/共享固定剧情，可以把对应 session 的 runtime 切片落盘为静态脚本，再将该 slug 发布给所有玩家。

### Customising the provider

- 直接使用示例 LLM 提供器：`packages/server/llmProvider.js`。它依赖 OpenRouter（`OPENROUTER_API_KEY`），默认模型为 `google/gemini-2.5-flash`，可用 `LLM_WRITE_MODEL` 覆盖。`\*`若需要提升思考深度，可设置 `LLM_WRITE_TEMPERATURE`、`LLM_THINK_MODEL`、`LLM_THINK_TEMPERATURE` 与 `LLM_THINK_REASON_TOKENS` 等环境变量启用 Gemini reasoning。启动方式：
  启动方式：
  ```bash
  cd packages/server
  OPENROUTER_API_KEY=sk-xxx WEBGAL_RUNTIME_PROVIDER=./llmProvider.js node index.js ../webgal
  ```
- 每次调用都会把 **输入提示（system/user）** 和 **输出脚本** 写到 `packages/server/logs/runtime-YYYYMMDD.log`（默认每次启动都会自动清空当日的日志；如需累计追加可设置 `WEBGAL_RUNTIME_LOG_APPEND=true`）。控制台只展示一条裁剪后的 preview（默认 200 字）。可用 `WEBGAL_RUNTIME_LOG_DIR`、`WEBGAL_RUNTIME_LOG_PREVIEW` 调整目录与截断长度。
- 运行时会使用滚动窗口预取（默认深度 2、并发 4、TTL 10 分钟）。需要调整时可设置：`WEBGAL_RUNTIME_PREFETCH_DEPTH`、`WEBGAL_RUNTIME_PREFETCH_CONCURRENCY`、`WEBGAL_RUNTIME_CACHE_TTL`（单位毫秒）。如果希望在服务器启动后立即为 plan.warmup.entry 做冷启动预取，可设置 `WEBGAL_RUNTIME_WARMUP=true`。
- 每个 runtime 切片默认要求 `WEBGAL_RUNTIME_SLICE_MIN=3`、`WEBGAL_RUNTIME_SLICE_MAX=9` 行，并在行数耗尽前写满细节。可以通过相同的环境变量调整上下限。
- 或者复制 `packages/server/runtimeSceneProvider.js` 到其他位置，实现自定义的 `getRuntimeSlice(gameSlug, sliceId)` 并 `module.exports`。
- 启动 server 时用 `WEBGAL_RUNTIME_PROVIDER=relative/path/to/custom-provider.js yarn workspace WebGAL-Server start` 指向它。
- provider 会收到：
  - `gameSlug`: `public/games` 下的目录名。
  - `sliceId`: 例如 `ai-demo/entry`（即 `runtime/*.txt` 的路径去掉 `.txt`）。
- 返回值必须是纯 WebGAL 脚本文本。这里面可以调用任意 LLM、RAG、后端接口等。

### Front-end details

- `packages/webgal/src/Core/util/prefetcher/scenePrefetcher.ts` skips any scene containing `/runtime/` to avoid prefetch errors.
- The sample game (`games/story-lab`) adds a third option in `scene/start.txt` that calls `runtime/ai-demo/entry.txt`, which hits the demo provider so you can see the flow end-to-end.
- `sceneFetcher` 会自动把 `X-WebGAL-Session` 头带到所有 `/games/...` 请求上，确保服务器能识别玩家会话并命中对应的 runtime 缓存。
- Lobby 通过 `GET /api/games` 获取所有 `public/games/*/meta.json` 汇总信息，玩家自助生成的副本会自动出现在卡片列表中（无需重新构建静态资源）。

Once your generator is ready, simply emit more slices via `changeScene: runtime/...;` or branch with `choose:` entries that point to other runtime slices. The engine still handles saves/loads as usual because the runtime slices live in the same scene pipeline.

### 长篇续写小技巧

如果未来需要让同一条支线连续生成几十行剧情，可参考故事船团在「[如何让你的 Gemini 不再短小，一口气生成万字长文？](https://www.53ai.com/news/LargeLanguageModel/2025061107543.html)」一文中的“接力续写”方法：

1. 把模型改为 stream 模式并设置 `maxOutputTokens` 为较高值（例如 65000），`stopSequences=[]`，提示词要求“除非达到输出上限，否则不要收束”。
2. 在服务端监听返回的 `finish_reason`。如果为 `MAX_TOKENS`，立刻把上一段输出作为“已有正文”，向同一个会话追加一条 “继续” 指令，再次触发生成。
3. 把多段输出拼接到同一支线的脚本或缓存中，直到模型主动结束或我们达到目标篇幅。

目前默认 3~9 行的 runtime 切片已能覆盖大部分场景，但如果要扩展成更长篇幅，可以沿用上述方案，实现“自动检测触顶 → 继续写”的接力机制。
